\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{enumerate,color,titletoc}%,mathrsfs}
\usepackage[pagebackref,colorlinks,linkcolor=red,citecolor=blue,urlcolor=blue,
hypertexnames=true]{hyperref}
\usepackage{url}
\usepackage{ulem}

\newtheorem{thm}{Theorem}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{claim}[thm]{Claim}
\newtheorem{corollary}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{conj}[thm]{Conjecture}
\theoremstyle{definition}
\newtheorem{remark}[thm]{Remark}
\newtheorem{exa}[thm]{Example}
\newtheorem{question}[thm]{Question}

\def\FF{\mathbb{F}}
\def\RR{\mathbb{R}}
\def\CC{\mathbb{C}}
\def\NN{\mathbb{N}}

\def\ax{\langle x \rangle}
\def\axs{\langle x, x^{\ast} \rangle}

\def\cI{\mathcal{I}}

\def\hard{\rm{hard}}
\def\fin{\rm{finite}}

\def\tr{\operatorname{Tr}}

%opening
\title{My Papers and Projects}
\author{Chris Nelson}
\date{}

\begin{document}

\maketitle

\begin{abstract}
Here is a big picture look
at my mathematics projects.
\end{abstract}

\tableofcontents

\section{To Do This Week}

\subsection{Math Papers}
\begin{enumerate}
 \item Push out papers
\end{enumerate}

\section{Papers Published}

\begin{itemize}
 \item Non-Commutative Polynomial Solutions to Partial Differential Equations,
{\em Integral Equations and Operator Theory} {\bf 74} (2012), no. 4,
527--585.
\item On real one-sided ideals in a free algebra, {\em J. Pure Appl.
	Algebra}, 2014, vol. 218, pp. 269-284. (with Jaka Cimpri\v c, J.
William Helton, I. Klep, and Scott McCullough).
\item A
	non-commutative real
	nullstellensatz corresponds to a non-commutative real ideal; algorithms, (with
	J. Cimpric, J. Helton, S. McCullough)
	Proc. London Math. Soc. (2013) 106 (5): 1060-1086.
	doi: 10.1112/plms/pds060
	\url{http://arxiv.org/abs/1105.4150}, 1--35.
\item On real
	one-sided ideals in a free algebra (with J. Cimpri\v c, J. W. Helton, I. Klep,
	S. McCullough), 
	{\em Journal of Pure and Applied Algebra},
	Volume 218, Issue 2, February 2014, Pages 269â€“284
\end{itemize}

\section{Papers Accepted for Publication}
\begin{itemize}
\item "Noncommutative polynomials nonnegative on a variety intersect
	a convex set", {\em J. Functional Analysis} (with J. W. Helton and
	I. Klep), \url{http://arxiv.org/abs/1308.0051}
\end{itemize}



\section{Papers Submitted for Publication}

\begin{itemize}
	\item Matrix LNSS paper
\end{itemize}

\section{Papers in Preparation}

\begin{itemize}
 \item ??Two-sided NSS (with J. Cimpri\v c, J.W.
Helton, S. McCullough)
 \item PPI paper
\end{itemize}

\section{Results Being Polished}

\begin{itemize}
\item
\end{itemize}


\section{Miscellaneous Results}

\begin{itemize}
\item Perfect positivstellensatz on path algebra
\item Trace convex in one symmetric variable if and only
if the non-commutative Hessian is a sum of squares plus commutators
\end{itemize}


\section{Problems I Am Working On}

\subsection{List}

\begin{enumerate}
 \item NSS for matrices of fixed dimension $n$.
 \begin{enumerate}
  \item Trickier than thought.  Can't just do $J = I + \mathcal{F}_n$, where
$\mathcal{F}_n$ is the space of polynomial identities of dimension $n$.
Example is $n = 1$ and $I = (x_1^2)$.
 \item Note that maybe could fix this with $\ast$.  Example: if $I = x_1^2$,
and $n = 1$, then
\[
 (x_1^*)^2x_1^2 = (x_1^*x_1)^2 \quad \Rightarrow \quad x_1 \in \sqrt[\rm
real]{I}.
\]
 \end{enumerate}
 \item When do matrices of polynomials commute?
 \item When do NC polys commute with coefficients in some other kind of
division algebra/ring.
 \item Soft NSS
 \item Hard NSS
 \item Classify $p$ such that $\mathcal{D}_p = \mathcal{D}_L$
 \begin{enumerate}
  \item Algorithmically take $p$ and convert $p$ into $L$
 \end{enumerate}
 \item Trace convexity
 \item Lance-Tapper
 \item If $f$ is a NC function such that $f$ respects direct sums and
orthogonal similarities.  Then is $f$ a power series of polys in $\FF\axs$?
\end{enumerate}



\subsection{Lance-Tapper}

I added a solution for ideals generated by analytic monomials to a paper with
collaborators.

I typed up a file with the insights I have had for future reference for times
when I work on this problem again.


\emph{Latest:} I have some strong (in my opinion) ideas for proving it in the
case of finitely generated ideals.  Actually, what I think I can prove is
stronger: if $I$ is a finitely generated ``real'' ideal, then $\sqrt{I} = I$.
This is a vast improvement over previous results.  I will let this simmer a bit.

\begin{exa}
Let $I$ be generated by the set
\[ \{ x_1(x_2^*x_2)^dx_1 \mid d \geq 2 \}.\]
Then $\sqrt{I} \neq I$.  Can we say more?
If $X$ is bounded, can one use the Spectral Theorem on $X_2^*X_2$ to show that
we must
have $X_1X_2^*X_2X_1 = 0$?

{\em Update:} Yes, using the Spectral Theorem as well as the Stone-Weierstrass
Theorem\footnote{This shows how important the basics are.  My first instincts
were not to use known results.  This is something I need to cultivate more.}, I
was able to prove it.
\end{exa}

\subsubsection{Commutators}

I briefly thought about finding a linear functional which killed an ideal and
also all commutators.  A unshrinkable word is never cyclically equivalent to a
square.

However, this approach seems less fruitful now that I know that the result is
not true in general for non-finitely-generated ideals.

\subsection{Left Nullstellensatz for Non-Finitely-Generated Ideals}

I know that
\[ \sqrt{I} = \bigcap_{(X,v)\ \text{finite}} I(\{(X,v)\}).\]
Therefore I need to show a real left ideal is contained in some finitely
generated real ideals.

I also know that
\[ \sqrt[\rm real]{I} = I\]
if $I$ is a real homogeneous ideal.  I don't know this in general.

\emph{Latest:} Here is a counterexample to the non-finitely generated case.
Let $I$ be generated by the set
\[ \{ x_1(x_2^*x_2)^dx_3 \mid d \geq 1\}.\]
In short, looking at the eigenvalues and eigenvectors of $X_2^*X_2 \succeq 0$,
if $(X,v) \in V(I)$, then we need to have $X_1X_2^*X_2X_3v = 0$.

\emph{Latest \#2:} It's also true that if $X$ is a tuple of bounded operators
on a Hilbert space then we can get this example to work.

\subsection{Hard Nullstellensatz}

Let $I \subset \FF\axs$ be a (two-sided) ideal.
Let $\sqrt[n]{I}$ be defined by
\[ \sqrt[n]{I} := \cI(V(I)^{(n)}),\]
and
\[ \sqrt{I} := \cI(V(I)) = \cI\left( \bigcap_{n \in \NN} V(I)^{(n)} \right).\]
Then ??Fix??
\[ \sqrt[n]{I} = \bigcap_{\substack{J \supseteq I\\ J \mbox{ real}\\
\dim(\FF\axs / J) \leq n}} J\]
and
\[ \sqrt{I} = \bigcap_{n \in \NN} \sqrt[n]{I} =
\bigcap_{\substack{J \supseteq I\\ J\mbox{ real}\\ \dim(\FF\axs
/ J) < \infty}} J.\]

The $\sqrt{I}$ part is really easy to prove.

The $\sqrt[n]{I}$ case will take more thought.
If we mean $\bigcap_J Z(J)$ such that $J$ is a real left ideal with
$\dim(\FF\axs/J) \leq J$, then this is correct.

\subsubsection*{Conjecture}

Suppose that $I$ is generated by analytic polynomials.
If $I \neq \FF\axs$, then $\sqrt[\hard]{I}$ is equal to
$I$ if and only if
$1 + \text{commutators} \not\in I$.

I know that if $1 + \text{commutators} \in I$, then $\sqrt[\hard]{I} = \FF\axs$.

\begin{proof}
If $I \subset J$, and $0 < \dim(\FF\axs / J) < \infty$, then we can
build a tuple of matrices easily such that $\vartheta(X) = 0$ if and only if
$\vartheta \in J$.  If $1 + \sum_i^{\fin} p_i q_i - q_i p_i \in I$, then this
implies that
\[ \tr\left(I_n + \sum_i^{\fin} p_i(X) q_i(X) - q_i(X) p_i(X)\right) = n,\]
which is a contradiction.
\end{proof}

Suppose $I \subset J$, and $0 < \dim(\FF\axs / J) < \infty$, and $pq - qp - 1
\in I$.  This implies that $f(p) \in J$ for some commutative polynomial $p \in
\FF[x_1]$.  It is straightforward to verify that
\[ f(p)q = qf(p) + f'(p),\]
which implies that $f'(p) \in J$.  Taking this all the way down, we see that $1
\in J$.

\emph{Example}:
\[ X=\begin{bmatrix}
      0&0&0\\1&0&1\\0&0&0
     \end{bmatrix}
\quad \mbox{and}
\quad
Y=\begin{bmatrix}
      0&0&0\\0&0&0\\1&0&1
     \end{bmatrix}
\]
This gives $XY-YX-X = 0$ but $X \neq 0$.

\subsubsection{Known Properties}

\begin{prop}
For any hard radical ideal $I$, the following hold
\begin{enumerate}
 \item $I$ is a $\ast$-ideal
 \item Whenever
\begin{equation}
\label{eq:sosPlusCom}
\sum_i^{\fin} p_i^*p_i + \sum_j^{\fin} (q_jr_j - r_jq_j) \in I,
\end{equation}
for some $p_i, q_j, r_j$, then each $p_i \in I$.
 \item Whenever
\[
 pq - 1 \in I
\]
for some $p,q$ then $qp - 1 \in I$ as well.
\end{enumerate}
\end{prop}

\begin{proof}
 If $X \in V(I)$, and $p \in \cI(V(I)) = I$, then $p(X) = 0$,
which implies that $p(X)^* = 0$.  Therefore $p^* \in I$.  This
gives (1).

For (2), suppose (\ref{eq:sosPlusCom}) holds.  Then if $X \in V(I)$, we see
\[
 \sum_i^{\fin} p_i(X)^*p_i(X) + \sum_j^{\fin} (q_j(X)r_j(X) - r_j(X)q_j(X)) = 0.
\]
Therefore
\[
 \operatorname{Tr} \left( \sum_i^{\fin} p_i(X)^*p_i(X) + \sum_j^{\fin}
(q_j(X)r_j(X) - r_j(X)q_j(X))\right) \]
\[= \sum_i^{\fin}
 \operatorname{Tr} \left(  p_i(X)^*p_i(X)\right) = 0,
\]
which implies that each $p_i(X) = 0$.  Therefore each $p_i \in I$.

For (3), suppose $pq - 1 \in I$.  If $X \in V(I)$, then $p(X)q(X) -
\operatorname{Id} = 0$, where $\operatorname{Id}$ denotes the identity matrix
of proper dimension.  Therefore $p(X)$ and $q(X)$ are inverses of each other,
so $q(X)p(X) = \operatorname{Id}$ as well.  Therefore $qp - 1\in I$.
\end{proof}

\begin{proof}[Alternate Proof of (3)]
Suppose $pq -1 \in I$.
 Suppose $I \subset J$, where $J$ is an ideal with finite co-dimension.
The finite co-dimension assumption implies that there exists some polynomial in
$q$ in $I$, that is,
\begin{equation}
\label{eq:plyInQ}
 q^n + a_{n-1} q^{n-1} + \cdots + a_0 \in I
\end{equation}
for some scalars $a_0, \ldots, a_{n-1}$.
Assume that (\ref{eq:plyInQ}) is the smallest polynomial in $q$ appearing in
$I$. If $1 \not\in J$ then this minimal polynomial has positive degree.
We see
\begin{align}
\notag
p(q^n + a_{n-1} q^{n-1} + \cdots + a_0)
&= (pq)(q^{n-1} + a_{n-1} q^{n-2} + \cdots + a_1) + a_0p\\
\notag
& = (pq - 1)(q^{n-1} + a_{n-1} q^{n-2} + \cdots + a_1)\\
\notag
& \quad + q^{n-1} + a_{n-1}
q^{n-2} + \cdots + a_1 + a_0p.
\end{align}
If $a_0 = 0$, then this implies that the polynomial
\[
 q^{n-1} + a_{n-1}
q^{n-2} + \cdots + a_1 \in I,
\]
which contradicts our minimality assumption.
Therefore $a_0 \neq 0$.

We then see
\begin{align}
\notag
q (q^{n-1} + a_{n-1}
q^{n-2} + \cdots + a_1 + a_0 p)
&= q^{n} + a_{n-1}q^{n-1} + \cdots + a_1 q + a_0qp\\
\notag
& = (q^{n} + a_{n-1}q^{n-1} + \cdots + a_1 q + a_0)\\
\notag
& \quad - a_0(qp-1).
\end{align}
Therefore $qp-1 \in I$.
\end{proof}

\begin{proof}[Algebraic Proof of (3)]
If $J$ has finite co-dimension, then $\FF\axs/J$ is a finite-dimensional ring,
and $[p][q] = [1]$.
The operation of left multiplication is therefore a bijection on the quotient
space: for each $r \in \FF\axs$, we have $[q][r] = 0$ implies that $[p][q][r] =
[r] = 0$, which shows injectivity.  It must be onto because it maps a finite
dimensional space into itself.  Therefore there exists some $s \in \FF\axs$ such
that $[q][s] = [1]$.  Therefore $[p][q][s] = [s] = [p]$, which shows $[s] =
[p]$, which shows $[q][p] = 1$.
\end{proof}

\begin{proof}[Matrix Proof of (3)]
I think a matrix proof essentially is the algebraic proof.
If $v$ is a vector, and $Qv = 0$, then $PQv = v = 0$.
Therefore $Q$ maps the space of vectors onto itself, and so given $w$ there
exists a $v$ such that$Qv = w$.  We see that $PQv = v = Pw$, so $QPw = w$.
Therefore $QP$ is the identity.
\end{proof}

\subsubsection{Idea}

Prove a Hilbert Basis Theorem like thing for the space $\{p(X) \mid X_k =
(x_{ijk})_{1 \leq i,j\leq N}\}$.
Is there something already like this?

\emph{Latest:} I notice that one can use dimensions to show there exist
polynomials which are $0$ on all $n \times n$ matrix tuples.

\subsubsection{Known Answers}

Let's look at the Hard NSS over just analytic polynomials.

\begin{exa}
In one variable, $\sqrt{I} = I$ for each two-sided ideal $I \subset \FF\ax$.
{\em Proof:} In one variable, $I$ is a principal ideal and furthermore has
finite codimension.  The result follows simply from here. \qed
\end{exa}

\begin{exa}
 Let $I \subset \FF\ax$ be the two-sided ideal generated by $x_1x_2 - 1$, in
two-variables.  Then $\sqrt{I}$ is generated by $x_1x_2 - 1$ and
$x_1x_2-x_2x_1$. {\em Proof:} If $X_1, X_2$ are matrices such that $X_1X_2 - 1
= 0$, then $X_1^{-1} = X_2$ and so $X_1, X_2$ commute, so $x_1x_2-x_2x_1 \in
\sqrt{I}$.  Further, $\sqrt{I}$ is contained in the two-sided ideal generated
by $x_1x_2 -1$ and $x_1x_2-x_2x_1$ since over $\CC$ we have $q(a) = 0$ where
$a_1a_2 - 1 =0$ iff $q$ is in the commutative ideal generated by $x_1x_2 - 1$.
\qed
\end{exa}

\begin{exa}
 If $I \subset \FF\ax$ is generated by $x_1x_2 - x_2x_1 + 1$, then $\sqrt{I} =
\FF\ax$. {\em Proof:} $x_1x_2 - x_2x_1 + 1$ always has positive trace, hence it
can never be $0$. \qed
\end{exa}



\subsection{Path Algebras}

I think that I can generalize some of my results to the case of path algebras.
(Specifically my Left Nullstellensatz and my Positivity stuff).

{\it Note:} I am somewhat waiting for my ppi paper to be done.


\subsection{Positivity Set of a Linear Pencil}

This is a question that Prof. Helton has been studying.
If $L$ is a linear pencil and $p$ is a NC polynomial, then ${\mathcal D}_L =
{\mathcal D}_p$ implies what about $p$?  We already have a positivstellensatz
for ${\mathcal D}_p \subset {\mathcal D}_L$.

\subsubsection{Known Examples}

\begin{exa}
If $p$ is of the form
\[
 p = L + L \left( \sum_{i}^{\rm finite} q_i^*q_i + \sum_j^{\rm finite} r_j^*Lr_j
\right) L
\]
then ${\mathcal D}_L = {\mathcal D}_p$.
\end{exa}

\begin{proof}
First, if $L(X) \succ 0$ then clearly $p(X) \succ 0$ as well.

Next, if $X$ is on the boundary of $D_L$, then there exists a vector $v$ and a
direction $H$ such that $L(X)v = 0$ and $v^*L'(X,H)v < 0$.  In this case
\[
 p(X)v = \left( \operatorname{Id} + L(X)\left[
 \sum_{i}^{\rm finite} q_i(X)^*q_i(X) + \sum_j^{\rm finite} r_j(X)^*L(X)r_j(X)
 \right]\right) L(X)v = 0
\]
and
\begin{align}
\notag
 v^*p'(X,H)v &= (L(X)v)^*\left( \left[ \sum_{i}^{\rm finite} q_i^*q_i +
\sum_j^{\rm finite} r_j^*Lr_j
\right] L\right)'(X,H)v \\
\notag
&+ v^*L'(X,H)\left( \sum_{i}^{\rm finite}
q_i(X)^*q_i(X) + \sum_j^{\rm finite} r_j(X)^*L(X)r_j(X)
\right) L(X)v\\
\notag
&+ v^*L'(X,H)v \\
\notag
&= v^*L'(X,H)v < 0.
\end{align}
Therefore $X$ is on the boundary of ${\mathcal D}_p$ as well.
\end{proof}

\begin{exa}
 If $q$ is a polynomial which is ``usually'' invertible and ${\mathcal D}_p =
{\mathcal D}_L$, then $q^*Lq$ also satisfies ${\mathcal D}_{q^*Lq} = {\mathcal
D}_{L}$.
\end{exa}

\begin{proof}
 We see that $\det(q^*Lq) = \det(q)^*\det(L)$, so $\det(q^*Lq)$ is usually $0$
only when $\det(L) = 0$.
\end{proof}

\begin{question}
 The examples I have found so far are of the form
 \[
  q^*pq
 \]
 where $p$ has the stronger property that if $L(X) \succeq 0$, $L(X)v = 0$ and
$v^*L'(X,H)v < 0$, then $P(X) \succeq 0$, $p(X)v = 0$, and $v^*p'(X,H)v < 0$.
Are these the only examples?
\end{question}

\begin{question}
 Let $I_L = \FF^{1 \times \ell}\axs L$ be the left module generated by the rows
of $L$.  Is it true that $\sqrt[L]{I_L} = I_L$?
\end{question}

\begin{question}
 If it is true that $\sqrt[L]{I_L} = I_L$, what is the set
 \[
  \{ p\in \FF^{\ell \times \ell}\axs \mid Lp \in I_L\}.
 \]
 I know that this set contains
 \[
  \{ q(L) \mid q(t) \in \FF[t]\}
 \]
 and
 \[
  \{q \in \FF^{\ell \times \ell}\axs \mid Lq = qL\}
 \]
\end{question}




\subsubsection{Examples where positivity sets not equal}

If $\tilde{L} = L + 1$, then ${\mathcal D}_{\tilde{L}} \supsetneq {\mathcal
D}_L$.

\subsection{Soft Zero Set}

Here is a question which, in part, relates to the positivity set of a linear
pencil.

\begin{question}
 Let $S \subset \FF\axs$ be a subset of $\FF\axs$.
 Compute the set
 \[
 \sqrt[\rm soft]{S}=
  \{ q \in \FF\axs \mid \det(q(X)) = 0 \mbox{ whenever } \det(p(X)) = 0 \mbox{
for each } p \in S \}.
 \]
\end{question}

\begin{question}
 Is there an easy result to be had if $S = \{p\}$?
\end{question}


\subsubsection{Known Results}

\begin{prop}
 If $p \in \sqrt[\rm soft]{S}$, then so is $qp$ and $pq$ for any $q \in
\FF\axs$.
\end{prop}

\begin{proof}
 If $\det(p(X)) = 0$ then $\det(q(X)p(X)) = \det(q(X))\det(p(X)) =
\det(p(X)q(X)) = 0$.
\end{proof}

\begin{prop}
 Given $p \subset \FF\axs$, let $I = \FF\axs p$ be the left ideal generated by
$p$.  Then $\sqrt[\rm real]{I} \subset \sqrt[\rm soft]{\{p\}}$.
\end{prop}

\begin{proof}
 If $\det(p(X)) = 0$, then there exists some nonzero vector $v$ such that $p(X)v
= 0$.  By the Left Nullstellensatz, we also have $q(X)v = 0$ for each $q \in
\sqrt[\rm real]{I}$.
\end{proof}

\begin{prop}
 The set $\sqrt[\rm soft]{\{p\}}$ is almost never an ideal.
\end{prop}

\begin{proof}
 Will appear in two-sided paper.
\end{proof}

\begin{prop}
 If $p_1 \cdots p_k$ is in a soft zero set, so is $p_{\sigma(1)} \cdots
p_{\sigma(k)}$ for each permutation $\sigma \in S_k$.
\end{prop}

\begin{proof}
 $\det(p_1(X) \cdots p_k(X)) = \det(p_1(X)) \cdots \det(p_k(X)) =
\det(p_{\sigma(1)}(X)\cdots p_{\sigma(k)}(X))$
\end{proof}

\begin{prop}
 A soft zero set is real and $\ast$-closed.
\end{prop}

\begin{proof}
 Easy.
\end{proof}

\begin{prop}
 If $I = \sqrt[\rm real]{\FF\axs p}$ has finite co-dimension, then $\sqrt[\rm
soft]{\{p\}}$ is
\[
 \sqrt[\rm
soft]{\{p\}} = Z(I) + \bigcap_{q \in \FF\axs} I q
\]
\end{prop}

\begin{proof}
First, suppose $\theta \in Z(I)$, $\iota \in I$, and $s \in \FF\axs$.
Suppose $\det(p(X)) = 0$.  We can choose $X$ so that it is ``irreducible''. Then
there exists some nonzero vector $v$ such that $p(X)v = 0$.  By the Left
Nullstellensatz, $\theta(X)v = \iota(X)v = 0$.  ??Not hard to show that
$\theta(X) = 0$.??  Therefore $\det(\theta(X) + \iota(X)s(X)) =
\det(\iota(X))\det(s(X)) = 0$.

 Conversely, there exists pair $(X,v)$ such that $I = \cI(\{(X,v)\})$.  Further,
$\FF\langle X, X^* \rangle$ is semisimple, so $\FF\langle X, X^* \rangle \cong
\bigoplus_{i=1}^{N} M_{n_i}(D_i)$, where each $D_i$ is one of $\RR$, $\CC$, or
$\mathbb{H}$.  Further, we can pick $X$ so that $X = \bigoplus_{i=1}^n X^{(i)}$,
where each $X^{(i)}$ is a tuple of square matrices on a subspace isomorphic to
$D_i^{n_i}$, and $v = \bigoplus_{i=1}^n v_i$, where each $v_i$ is a nonzero
vector on a subspace isomorphic to $D_i^{n_i}$.

If $q \in \sqrt[\rm soft]{\{p\}}$, then $\det(q(X^{(i)})) = 0$ for each $i$
since $p(X^{(i)})v_i = 0$.  Therefore there exists some nonzero vector $w_i$
such that $q(X^{(i)})w_i = 0$.  Since $\FF\langle X, X^* \rangle \cong
\bigoplus_{i=1}^{N} M_{n_i}(D_i)$, there exists some $r \in \FF\axs$ such that
$r(X)$ is an invertible matrix which maps $v$ to $\bigoplus_{i=1}^n w_i$.
Therefore
\[q(X)r(X)v = \bigoplus_{i=1}^n q(X^{(i)})w_i = 0.\]
This implies that $\iota = qr \in I$.

Further, since $\FF\langle X, X^* \rangle \cong
\bigoplus_{i=1}^{N} M_{n_i}(D_i)$, there exists some $s \in \FF\axs$ such that
$s(X) = r(X)^{-1}$.  Therefore
\[
 q(X) - q(X)r(X)s(X) = 0,
\]
which implies that $\theta = q - qrs \in \cI_{\rm hard}(\{X\})$.  It is not hard
to show that $\cI_{\rm hard}(\{X\}) = Z(I)$.  Therefore
\[
 q = (q - qrs) + (qr)s = \theta + \iota s \in Z(I) + \bigcap_{q \in \FF\axs} I
q.
\]
\end{proof}

\begin{exa}
 If $p = x^3$ and $I = \sqrt[\rm real]{\FF\axs x^3} = \FF\axs x^3$, then $Z(I)
= \{0\}$.  Note that $x \in \cI[\rm soft]{\{p\}}$ but $x \not\in Z(I) +
\bigcup_{q \in \FF\axs} Iq$.
\end{exa}

\subsubsection{Irreducible}

Suppose $p, q$ are both irreducible and distinct, and the setting is restricted
to just analytic polynomials.  In this case, probably $q \theta \not\in I_p$ for
any $\theta \not\in I_p$.  I need to look at when $q \theta \in I_p$.  Then,
one can leverage this, maybe, to find a ``flat'' ideal $J$ such that $q \theta
\not\in J$.

\subsubsection{Idea 2013.02.22}

If $I$ is a left ideal, what is the set
\[
 C(I) := \{q \mid Iq \subset I \}
\]
This set is a subring.  If $I = \FF\ax p$, and $p$ is irreducible, then I think
$C(I) = I$ is probably true.  If $I = \FF\axs x_1 x_2 x_1$, then $x_2 x_1 \in
C(I) \setminus I$.

If I can learn about this set, can I then leverage that to constructing a left
ideal with finite codimension such that $q \not\in C(I)$?

\subsubsection{Linear Pencils}

Could the linear pencil case be easier?

\subsection{Commuting Matrices}

What if we look only at the set of tuples of commuting matrices?

\subsubsection{Nullstellensatz for Commuting Matrices}

The answer might be $\sqrt{I} = I + {\rm Commutator\ Ideal}$.
Also note that this is a hard NSS.

\begin{proof}[Sketch of Proof]
 Let $p^k \in I$ but $p \not\in I$.  Let each
$X_i$ be
 \[
  X_i = a_i \begin{pmatrix}
             1&x_i&0&\cdots&0\\
             0&1&x_i&\cdots&0\\
             \vdots&\vdots&\vdots&\ddots&\vdots\\
             0&0&0&\cdots&x_i\\
             0&0&0&\cdots&1
            \end{pmatrix}
 \]
 The diagonal of $p(X)$ is $p(a)$ and the off diagonal is
 \[
  \sum_{i=1}^g a_i p_{x_i}(a) x_i
 \]
 Pick $a \in V(I)$ so that it kills $p$
 but not at least one of the $p_{x_i}(a)$. ??Why can one do this??
 Then there exists an $x$ which makes the off diagonal nonzero.
 One can show then that $p(X) \neq 0$ but $p(X)^k = 0$.
 ??There are a lot of details to fix on this sketch.  For example, this seems
to work well if $I$ is singly generated, but what about other cases? ??

Also note that the $X_i$ above kill the ideal generated by polynomials of the
form
\[
 (x_{i_1} - a_{i_1}) \cdots (x_{i_k} - a_{i_k})
\]
where $i_1, \ldots, i_k$ are some (possibly repeating) indices.
\end{proof}

\subsubsection{Positivstellensatz}

Don't know.

\section{Things I Am Reading About}

\subsection{Centralizers and Factorization of NC Polynomials}

I read that two NC polynomials $p, q \in \FF\ax$ commute
if and only if there is some common polynomial $r \in \FF\ax$ and some
univariate polynomials $a, b \in \FF[t]$ such that $p = a(r)$ and $q = b(r)$.
This result is {\it Bergman's Centralizer Theorem}.

\begin{question}
What is the analog of Bergman's Centralizer Theorem for $\FF^{\ell \times
\ell}\ax$?
\end{question}

\subsubsection{Factorization}

A homogeneous polynomial in $\FF\ax$ can be uniquely factored into irreducibles
up to scalar multiplication.  This unique factorization includes a unique order
of factors.

A non-homogeneous polynomial cannot necessarily be uniquely factored.

\begin{exa}
 Let $p \in \FF\ax$ and $q \in \FF[t]$.  Then the commutative polynomial $q$ can
be uniquely factored as $q = q_1 \cdots q_k$ into irreducible factors.
We see then that if $\sigma \in S_k$ then
\[
 q(p) = q_{\sigma(1)}(p) \cdots q_{\sigma(k)}(p).
\]
This gives at least $k!$ different factorizations of $p$.
\end{exa}

\begin{exa}
 If $q \in \FF[t]$, then
 \[
  x_1q(x_2x_1) = q(x_1x_2)x_1.
 \]
\end{exa}

\begin{question}
 Are these the only examples?
\end{question}

\begin{question}
 Next try $\FF^{\ell \times \ell}\ax$.
\end{question}


\subsection{Path Algebras}

I think I could generalize some stuff to path algebras.
Specifically, the set-up is to let
$x_1, \ldots, x_g$ represent $m_i \times n_i$ matrices.

\subsection{Connes}

One can prove the Connes conjecture if one can prove the following:

\begin{conj}
 Let $q = 1 - x^*x$.  If $p \in \FF\langle x \rangle$ is not equal to an element
of the quadratic module generated by $q$ and some commutators, then there exists
an $X$ such that $\operatorname{Tr}(p(X)) < 0$.
\end{conj}

\subsection{Various Papers}

I picked out various papers from Helton.
I also have some on moment matrices.

\subsection{Invariant Subspaces and Operator Calculus}

I want to know more about this topic.

\section{Backburner}

\subsection{Results That I Might Not Publish}

\subsection{Problem Posed to Me}

Let $p \in \RR\langle x,a \rangle$ be a symmetric polynomial in symmetric
variables.
Then $p_x(x,a)[h]$ is of the form
\[ p_x(x,a)[h] = (\pi V(x)[1])^T(V(x)[h]), \]
where $V(x)[h]$ is some border vector and $\pi$ is some permutation.
Suppose that $q \in \operatorname{span} V(x)[1]$ and that $q(X)v = 0$ whenever
$p(X)v = 0$.  What can we say about $q$?
What if we know that the map
\[ H \mapsto p_x(X,A)[H]\]
is onto for a reasonably large class of $(X,A)$?

\begin{exa}
 If $p = f^Tf$, then $p_x(x)[h]$ is equal to
\[ p_x(x)[h] = (f_x(x)[h])^Tf + f^T(f_x(x)[h]).\]
The map in question is not onto for $(X,v) \in V(\{f\})$ since
for any $H$,
\[v^*\left( [f_x(X)[H]]^Tf(X) + f(X)^T[f_x(X)[H]]\right)v = 0. \]
\end{exa}

What can I say about the following: what if $p(X)v = 0$ and $p_x(X)[H]v = 0$?
What if in this case we have $v^*p_{xx}(X)[H]v \geq 0$?

\subsection{Trace Convexity}

I have a result for one variable.
Is there any way to get more out of it?

\end{document}
